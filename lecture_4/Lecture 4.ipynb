{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eGKXi-Ylm_Jg"
   },
   "outputs": [],
   "source": [
    "Quote1 = \"In the balance of life, accounting is the equilibrium that keeps everything in check.\" #Olivia Martinez\n",
    "Quote2 = \"Accounting is not just about counting beans; it’s about making every bean count.\"#William Reed\n",
    "Quote3 = \"Accounting is the language of business.\" #Warren Buffett\n",
    "\n",
    "Quotes=[Quote1,Quote2,Quote3]\n",
    "\n",
    "#Source: https://www.acecloudhosting.com/blog/motivational-quotes-accountants/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Quotes[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in Quote1.split():\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DggggmWFfOIG",
    "outputId": "b87d3794-bce9-4a01-ac12-879c61670875"
   },
   "outputs": [],
   "source": [
    "def tokenizer(doc):\n",
    "  \"\"\"\n",
    "  Tokenizes the input document into a list of tokens\n",
    "  \"\"\"\n",
    "  tokens=[]\n",
    "  for token in doc.split():\n",
    "    tokens.append(token)\n",
    "  return tokens\n",
    "\n",
    "tokenizer(Quote1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VW_snD0hgRIV",
    "outputId": "80da9261-5600-4676-8f59-42bba07527c2"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp=spacy.load(\"en_core_web_sm\", enable=[\"tokenizer\"])\n",
    "\n",
    "def tokenizer(doc):\n",
    "  \"\"\"Tokenizes the input document into a list of tokens\"\"\"\n",
    "  tokens=[]\n",
    "  for token in nlp(doc):\n",
    "    tokens.append(token.text.lower())\n",
    "  return tokens\n",
    "\n",
    "tokenizer(Quote1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jX7fBXWsoqHy",
    "outputId": "225ce2ff-21b2-4870-d65b-67fbf03a91f5"
   },
   "outputs": [],
   "source": [
    "def tokenizer(doc):\n",
    "    \"\"\"Tokenizes the input document into a list of tokens\"\"\"\n",
    "    tokens=[]\n",
    "    for token in nlp(doc):\n",
    "        if not token.is_punct:\n",
    "            tokens.append(token.text.lower())\n",
    "    return tokens\n",
    "\n",
    "tokenizer(Quote1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6Sh908vjp-hI",
    "outputId": "27bcebe7-7f73-4b4a-83d3-5ba296ffeb0b"
   },
   "outputs": [],
   "source": [
    "def tokenizer(doc):\n",
    "    \"\"\"Tokenizes the input document into a list of tokens\"\"\"\n",
    "    return [token.text.lower() for token in nlp(doc) if not token.is_punct]\n",
    "\n",
    "tokenizer(Quote1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UuRcbTbDtRh4",
    "outputId": "755525fa-121f-4442-f061-8ba4013173ce"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer=CountVectorizer(tokenizer=tokenizer, token_pattern=None)\n",
    "vectorizer.fit(Quotes)\n",
    "\n",
    "features=vectorizer.get_feature_names_out()\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "id": "RaXse59Jvcb2",
    "outputId": "91a350a8-70e8-4aee-9af4-46e3aaf92572"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "bow=vectorizer.transform(Quotes)\n",
    "df_bow = pd.DataFrame(bow.toarray(),columns=vectorizer.get_feature_names_out())\n",
    "df_bow.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yXjI3M43vcjK"
   },
   "outputs": [],
   "source": [
    "Quote4=\"In the symphony of financial wisdom, the best accountants are the virtuosos of economic insight.\"\n",
    "\n",
    "bow_q4=vectorizer.transform([Quote4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xHPTguqCvcoF"
   },
   "source": [
    "# Sentiment Analysis: IMDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ld_tdKGNCfdF",
    "outputId": "8cedca13-42b2-4210-cb89-0486d2d3a766"
   },
   "outputs": [],
   "source": [
    "#Download .csv files:\n",
    "#!gdown '1Ikw-u9MQZzne7rJFyQTCn8HzbGiVNOQA'\n",
    "#!gdown '1hqDE1N4tsfGb9gpRfi9hDH4dTBoJLVC1'\n",
    "\n",
    "#Import libraries:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import spacy\n",
    "nlp=spacy.load(\"en_core_web_sm\", enable=[\"tokenizer\"])\n",
    "\n",
    "#Tokenizer function:\n",
    "def tokenizer(doc):\n",
    "    \"\"\"Tokenizes the input document into a list of tokens\"\"\"\n",
    "    return [token.text.lower() for token in nlp(doc) if not token.is_punct]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WHRfCrJfphe9"
   },
   "outputs": [],
   "source": [
    "#Read csv files into pandas DataFrames:\n",
    "df_train=pd.read_csv('train_imdb.csv')\n",
    "df_test=pd.read_csv('test_imdb.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "fzArnRn5ps3-",
    "outputId": "af996936-e108-4590-c658-528eb2102e8a"
   },
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "eoNLuzDdSTRB",
    "outputId": "13cb86ea-2425-4fb9-b871-ed4e30e87544"
   },
   "outputs": [],
   "source": [
    "df_train['review'][150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "ttG_oJIZTxEm",
    "outputId": "dc2c54d8-2471-4bc7-bf62-257454da89ff"
   },
   "outputs": [],
   "source": [
    "df_train['review'][14608]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UEDNeeF-pueT",
    "outputId": "c3373b32-760a-4653-b155-2dde27fbb9cc"
   },
   "outputs": [],
   "source": [
    "print(f\"Number of observations in training set: {len(df_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 92
    },
    "id": "_TpK3iXXqHlj",
    "outputId": "91c34879-b687-4cd5-aaa2-1ef9a88569e7"
   },
   "outputs": [],
   "source": [
    "#Bag-of-words representation is implemented in CountVectorizer\n",
    "vectorizer = CountVectorizer(tokenizer=tokenizer, token_pattern=None)\n",
    "#Create a dictionary of tokens\n",
    "vectorizer.fit(df_train['review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CV9htCSvullF",
    "outputId": "1d54a801-50e8-4931-b265-03abf2a850e9"
   },
   "outputs": [],
   "source": [
    "features=vectorizer.get_feature_names_out()\n",
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QfY8lzw2k-Pp",
    "outputId": "e70c3fc4-9080-4881-9add-a410c078a48a"
   },
   "outputs": [],
   "source": [
    "features[0:80]\n",
    "#Most of these numbers don't appear to have immediate semantic meanings, except for 007"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JT71l6B9x7zv",
    "outputId": "d3320ef8-24cd-4e32-b109-928ebf7ed163"
   },
   "outputs": [],
   "source": [
    "features[39000:39080]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pgtS7SEjzi_l",
    "outputId": "81b17580-6267-41cd-8151-1ee7997a9ed1"
   },
   "outputs": [],
   "source": [
    "features[::1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zI6J9_-1QTqW"
   },
   "outputs": [],
   "source": [
    "#Create a bag of words:\n",
    "X_train=vectorizer.transform(df_train['review'])\n",
    "y_train=df_train['sentiment']\n",
    "#Create a bag of words:\n",
    "X_test=vectorizer.transform(df_test['review'])\n",
    "y_test=df_test['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 301
    },
    "id": "fwLOvdDvaYff",
    "outputId": "e874ec4b-c886-44b2-f08b-c650613a5179"
   },
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "# Create a dictionary with word frequencies\n",
    "word_frequencies = dict(zip(feature_names, X_train.sum(axis=0).A1))\n",
    "\n",
    "# Create and generate a word cloud image:\n",
    "#wordcloud = WordCloud().generate(text)\n",
    "wordcloud = WordCloud(width=750, height=400,\n",
    "background_color='white').generate_from_frequencies(word_frequencies)\n",
    "\n",
    "# Display the generated image:\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.savefig(\"wordcloud1.png\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zF4wyeHsqUiG"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logistic = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oYQoZOLEqZc5",
    "outputId": "9c626d48-1c30-4816-aca0-d590a84c50f2"
   },
   "outputs": [],
   "source": [
    "logistic.fit(X_train, y_train)\n",
    "logistic.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fhEYvOz-4Y4S",
    "outputId": "d62403eb-ba4d-460e-d308-6ee0494d35a2"
   },
   "outputs": [],
   "source": [
    "logistic.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J7deyxER0VEz",
    "outputId": "b8721483-b013-46a3-8489-543ded535bb7"
   },
   "outputs": [],
   "source": [
    "vectorizer=CountVectorizer(tokenizer=tokenizer, token_pattern=None, min_df=5)\n",
    "vectorizer.fit(df_train['review'])\n",
    "features=vectorizer.get_feature_names_out()\n",
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T-rM220G8AWk",
    "outputId": "fad34b72-5ac5-4d48-d3ee-aa9abee12754"
   },
   "outputs": [],
   "source": [
    "features[0:80]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IlROTHsO8Aep",
    "outputId": "9f2e3335-f376-40f5-e48d-b3490367e306"
   },
   "outputs": [],
   "source": [
    "features[4500:4580]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pKVzQLQm-XF6",
    "outputId": "020d1331-522a-4dff-90ab-e18196d31e9c"
   },
   "outputs": [],
   "source": [
    "#Create a bag of words:\n",
    "X_train=vectorizer.transform(df_train['review'])\n",
    "y_train=df_train['sentiment']\n",
    "#Create a bag of words:\n",
    "X_test=vectorizer.transform(df_test['review'])\n",
    "y_test=df_test['sentiment']\n",
    "\n",
    "#Refit the logistic model:\n",
    "logistic = LogisticRegression()\n",
    "logistic.fit(X_train, y_train)\n",
    "logistic.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BcC3CiZV-XO4",
    "outputId": "c0240170-7a9e-4d9a-8a18-cbebb271f99b"
   },
   "outputs": [],
   "source": [
    "logistic.score(X_test, y_test)\n",
    "#Note this doesn't improve our model fit, but we have fewer features to deal with. Having fewer features should speed up performance and removing useless features may benefit interpretability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 301
    },
    "id": "qak8cPyia85j",
    "outputId": "dcd51479-2629-46dc-f0f0-a693e94486e0"
   },
   "outputs": [],
   "source": [
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "# Create a dictionary with word frequencies\n",
    "word_frequencies = dict(zip(feature_names, X_train.sum(axis=0).A1))\n",
    "\n",
    "# Create and generate a word cloud image:\n",
    "#wordcloud = WordCloud().generate(text)\n",
    "wordcloud = WordCloud(width=750, height=400, background_color='white').generate_from_frequencies(word_frequencies)\n",
    "\n",
    "# Display the generated image:\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.savefig(\"wordcloud2.png\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9tulHRq3rBt9"
   },
   "source": [
    "# Remove stopwords\n",
    "\n",
    "These words are used frequently and might not be informative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "juUGyKWkrA-P"
   },
   "outputs": [],
   "source": [
    "stop_words = spacy.lang.en.stop_words.STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5gHef5vBthrO",
    "outputId": "91dacdf5-d8fd-416d-b040-70e08ee60d7f"
   },
   "outputs": [],
   "source": [
    "list(stop_words)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yOKZDAlbALVj",
    "outputId": "186736f4-efb4-46f3-bec9-843dc1124267"
   },
   "outputs": [],
   "source": [
    "len(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "InP3Q4FmHQpq"
   },
   "outputs": [],
   "source": [
    "#Adjust the tokenizer function:\n",
    "def tokenizer(doc):\n",
    "    \"\"\"Tokenizes the input document into a list of tokens\"\"\"\n",
    "    tokens=[]\n",
    "    for token in nlp(doc):\n",
    "        if not token.is_punct and not token.is_stop:\n",
    "            tokens.append(token.text.lower())\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6Y51ihCht_VZ"
   },
   "outputs": [],
   "source": [
    "vectorizer=CountVectorizer(tokenizer=tokenizer, token_pattern=None, min_df=5)\n",
    "#Create a dictionary\n",
    "vectorizer.fit(df_train['review'])\n",
    "#Create a bag of words for the training set\n",
    "X_train=vectorizer.transform(df_train['review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VbN0Is_FuS7x",
    "outputId": "837376cb-35b8-469b-f505-e896b5f8e327"
   },
   "outputs": [],
   "source": [
    "#Number of features reduced from 27,475 to 27,169. This means 306 our of 318 stop words were used in the reviews\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k2ODQTLZuv20"
   },
   "outputs": [],
   "source": [
    "#Create new bag of words for text set:\n",
    "X_test=vectorizer.transform(df_test['review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 214
    },
    "id": "Sge12JePu-Sx",
    "outputId": "e619ec90-8080-4bc3-97d5-7aefa643f3a6"
   },
   "outputs": [],
   "source": [
    "#Fit logistic regression to training set:\n",
    "logistic.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Opeyi3yNvEmt",
    "outputId": "c874092c-4452-4728-e7b6-cb70970af988"
   },
   "outputs": [],
   "source": [
    "logistic.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ctuGRG-b2xWC",
    "outputId": "fe10e079-e1db-46f5-c155-497f0c77a3ca"
   },
   "outputs": [],
   "source": [
    "!pip install mglearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 457
    },
    "id": "2xP4XWC8R68t",
    "outputId": "81937e44-2da7-43f3-d470-b648bef847a8"
   },
   "outputs": [],
   "source": [
    "#Examine model coefficients\n",
    "import mglearn\n",
    "feature_names=vectorizer.get_feature_names_out()\n",
    "mglearn.tools.visualize_coefficients(logistic.coef_, feature_names, n_top_features=40)\n",
    "#Display coefficients that are predictive of positive (blue) and negative (red) reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NpxkgcK-bTyk",
    "outputId": "01c3b8cc-12a3-4bcb-e8b7-a2f34f6722d7"
   },
   "outputs": [],
   "source": [
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "# Create a dictionary with word frequencies\n",
    "word_frequencies = dict(zip(feature_names, X_train.sum(axis=0).A1))\n",
    "\n",
    "# Create and generate a word cloud image:\n",
    "#wordcloud = WordCloud().generate(text)\n",
    "wordcloud = WordCloud(width=750, height=400, background_color='white').generate_from_frequencies(word_frequencies)\n",
    "\n",
    "# Display the generated image:\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.savefig(\"wordcloud3.png\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OsdWFR001Ftt",
    "outputId": "76e7a472-2a54-4cbe-9e8c-12649ba86077"
   },
   "outputs": [],
   "source": [
    "print(len(feature_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hhf-bKHbWqOl"
   },
   "source": [
    "**Remove number like tokens**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aZ_b-8P7WvZK",
    "outputId": "683ce055-54ea-4c7a-c0df-1350ba08c3f0"
   },
   "outputs": [],
   "source": [
    "#Adjust the tokenizer function:\n",
    "def tokenizer(doc):\n",
    "    \"\"\"Tokenizes the input document into a list of tokens\"\"\"\n",
    "    tokens=[]\n",
    "    for token in nlp(doc):\n",
    "        if not token.is_punct and not token.is_stop and not token.like_num:\n",
    "            tokens.append(token.text.lower())\n",
    "    return tokens\n",
    "\n",
    "vectorizer=CountVectorizer(tokenizer=tokenizer, token_pattern=None, min_df=5)\n",
    "#Create a dictionary\n",
    "vectorizer.fit(df_train['review'])\n",
    "#Create a bag of words for the training set\n",
    "X_train=vectorizer.transform(df_train['review'])\n",
    "X_test=vectorizer.transform(df_test['review'])\n",
    "\n",
    "logistic.fit(X_train, y_train)\n",
    "logistic.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 462
    },
    "id": "5MxgQXPEXCuw",
    "outputId": "3d091d9c-acca-4c18-e2e0-e27c900b82b2"
   },
   "outputs": [],
   "source": [
    "#Examine model coefficients\n",
    "feature_names=vectorizer.get_feature_names_out()\n",
    "mglearn.tools.visualize_coefficients(logistic.coef_, feature_names, n_top_features=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 301
    },
    "id": "n5EDc5_sZZd0",
    "outputId": "5fd7dffa-35a7-4d31-b116-6875c7b7c5c6"
   },
   "outputs": [],
   "source": [
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "# Create a dictionary with word frequencies\n",
    "word_frequencies = dict(zip(feature_names, X_train.sum(axis=0).A1))\n",
    "\n",
    "# Create and generate a word cloud image:\n",
    "#wordcloud = WordCloud().generate(text)\n",
    "wordcloud = WordCloud(width=750, height=400, background_color='white').generate_from_frequencies(word_frequencies)\n",
    "\n",
    "# Display the generated image:\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.savefig(\"wordcloud4.png\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q_1uIh_b1EYI",
    "outputId": "5a7f134e-2704-453b-91c2-39449cca0c4b"
   },
   "outputs": [],
   "source": [
    "print(len(feature_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KL02M5eMS_aE"
   },
   "source": [
    "# N grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PQG44f3SLJYE",
    "outputId": "dd746bd2-1933-445e-8575-70041ae46d7b"
   },
   "outputs": [],
   "source": [
    "Quote1=\"In the balance of life, accounting is the equilibrium that keeps everything in check.\"\n",
    "\n",
    "vectorizer = CountVectorizer(ngram_range=(2,2))\n",
    "vectorizer.fit_transform([Quote1])\n",
    "vectorizer.get_feature_names_out()\n",
    "\n",
    "\n",
    "#ngram_range parameter sets the minimum length and the maximum lengths of the sequence of tokens that are considered:\n",
    "#(1,1)= unigrams\n",
    "#(2,2)= bigrams\n",
    "#(3,3)= trigrams\n",
    "#(1,2) = unigrams+bigrams\n",
    "\n",
    "#Typically set the minimum at one. Bigrams typically help too, as might 5-grams. However, this may lead to overfitting as there would be many very specific features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cNUcOpNq9a7W"
   },
   "source": [
    "# Sentiment analysis with bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "vLkMLRSBi_6e"
   },
   "outputs": [],
   "source": [
    "vectorizer=CountVectorizer(tokenizer=tokenizer, token_pattern=None,\n",
    "                           min_df=5, ngram_range=(1,2))\n",
    "\n",
    "vectorizer.fit(df_train['review'])\n",
    "X_train=vectorizer.transform(df_train['review'])\n",
    "X_test=vectorizer.transform(df_test['review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "EC55rgDrf2dP"
   },
   "outputs": [],
   "source": [
    "feature_names=vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "W5ChfUpsgG7f",
    "outputId": "cb4286e4-b08a-47a4-9606-c0e26d36ca20"
   },
   "outputs": [],
   "source": [
    "feature_names[3000:3020]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "X3i-qwYxcUUc"
   },
   "outputs": [],
   "source": [
    "#Examine performance of logistic regression after including bi-grams. Show coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "FnmYFfFtq2hx",
    "outputId": "daff1034-0997-4928-da28-12536d0e8f6d"
   },
   "outputs": [],
   "source": [
    "y_train=df_train['sentiment']\n",
    "y_test=df_test['sentiment']\n",
    "logistic.fit(X_train,y_train)\n",
    "logistic.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "3XXLHzfgrbNk",
    "outputId": "b55e61f5-a126-4e0d-c428-8c10a424af79"
   },
   "outputs": [],
   "source": [
    "!pip install mglearn\n",
    "import mglearn\n",
    "mglearn.tools.visualize_coefficients(logistic.coef_, feature_names, n_top_features=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "9ZCWKhcvsd05",
    "outputId": "6a372d8f-8476-47f6-bf66-de1b9ae34f3e"
   },
   "outputs": [],
   "source": [
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "# Create a dictionary with word frequencies\n",
    "word_frequencies = dict(zip(feature_names, X_train.sum(axis=0).A1))\n",
    "\n",
    "# Create and generate a word cloud image:\n",
    "#wordcloud = WordCloud().generate(text)\n",
    "wordcloud = WordCloud(width=750, height=400, background_color='white').generate_from_frequencies(word_frequencies)\n",
    "\n",
    "# Display the generated image:\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.savefig(\"wordcloud5.png\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "Mbj5K9wA1Czf",
    "outputId": "3bf26fd6-96d3-4a59-d0c2-ccd118d102fd"
   },
   "outputs": [],
   "source": [
    "print(len(feature_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J1gpA00XsqVA"
   },
   "source": [
    "# Advanced tokenization:\n",
    "\n",
    "We can improve on the first step in our bag-of-words model: tokenization\n",
    "\n",
    "We can try to extract some normal form of a word.\n",
    "\n",
    "Two approaches: stemming and lemmatization\n",
    "\n",
    "**Stemming:** representing each word using its stem\n",
    "\n",
    "**Lemmatization:** rely on a dictionary of known word forms while taking into account the role of a word in a sentence to create a standardized form of the word, referred to as the lemma.\n",
    "\n",
    "**Token:** A token simply refers to an individual part of a sentence having some semantic value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "SkJxGy8x8DlI",
    "outputId": "fab02e3f-553f-4cdc-d3dc-11796a06078b"
   },
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer #Also known as Porter2 stemmer\n",
    "stemmer=SnowballStemmer(language='english')\n",
    "\n",
    "\n",
    "def stemmer_tokenizer(doc):\n",
    "    \"\"\"Returns a list of stemmed tokens extracted from the document\"\"\"\n",
    "    tokens=[]\n",
    "    for token in nlp(doc):\n",
    "        if not token.is_punct and not token.is_stop and not token.like_num:\n",
    "            tokens.append(stemmer.stem(token.text))\n",
    "    return tokens\n",
    "\n",
    "x=stemmer_tokenizer(\"The accountant forgot to do the accounting for certain accounts and subsequently was kept accountable.\")\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "Cvm1iZPRYT1y",
    "outputId": "c19c761d-f1db-41c3-ee4f-251e5f4ddf95"
   },
   "outputs": [],
   "source": [
    "nlp=spacy.load(\"en_core_web_sm\", enable=[\"tokenizer\"])\n",
    "vectorizer=CountVectorizer(tokenizer=stemmer_tokenizer, min_df=5, token_pattern=None, ngram_range=(1,2))\n",
    "vectorizer.fit(df_train['review'])\n",
    "X_train=vectorizer.transform(df_train['review'])\n",
    "X_test=vectorizer.transform(df_test['review'])\n",
    "\n",
    "logistic.fit(X_train,y_train)\n",
    "logistic.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "ByzPPNYtBu3T",
    "outputId": "5c4bede4-62d3-41ac-f59b-249715db6685"
   },
   "outputs": [],
   "source": [
    "import mglearn\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "mglearn.tools.visualize_coefficients(logistic.coef_, feature_names, n_top_features=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "m_CX9RDbBvMl",
    "outputId": "d4be850b-443c-4e94-81fc-7ced366933cb"
   },
   "outputs": [],
   "source": [
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "# Create a dictionary with word frequencies\n",
    "word_frequencies = dict(zip(feature_names, X_train.sum(axis=0).A1))\n",
    "\n",
    "# Create and generate a word cloud image:\n",
    "#wordcloud = WordCloud().generate(text)\n",
    "wordcloud = WordCloud(width=750, height=400, background_color='white').generate_from_frequencies(word_frequencies)\n",
    "\n",
    "# Display the generated image:\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.savefig(\"wordcloud6.png\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "-utZVRtfLeMw",
    "outputId": "df6842ab-f781-4d99-fcd8-f707042c3c17"
   },
   "outputs": [],
   "source": [
    "print(len(feature_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "LMZk6jvV-oRE",
    "outputId": "4707d267-6d32-437d-ef51-2f37c14f299d"
   },
   "outputs": [],
   "source": [
    "nlp=spacy.load(\"en_core_web_sm\", disable=[\"parser\", \"ner\", \"textcat\"])\n",
    "\n",
    "def lemma_tokenizer(doc):\n",
    "    \"\"\"Returns a list of lemmatized tokens extracted from the document\"\"\"\n",
    "    tokens=[]\n",
    "    for token in nlp(doc):\n",
    "        if not token.is_punct and not token.is_stop and not token.like_num:\n",
    "            tokens.append(token.lemma_)\n",
    "    return tokens\n",
    "\n",
    "x=lemma_tokenizer(\"The accountant forgot to do the accounting for certain accounts and subsequently was kept accountable.\")\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tOqRfnon7oGl"
   },
   "outputs": [],
   "source": [
    "vectorizer=CountVectorizer(tokenizer=lemma_tokenizer, min_df=5, ngram_range=(1,2), token_pattern=None)\n",
    "vectorizer.fit(df_train['review'])\n",
    "X_train=vectorizer.transform(df_train['review'])\n",
    "X_test=vectorizer.transform(df_test['review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CgxfVDajdxdk",
    "outputId": "fa21be1f-28c4-4bdf-ccec-c2a7e2b00a7b"
   },
   "outputs": [],
   "source": [
    "logistic.fit(X_train,y_train)\n",
    "logistic.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 475
    },
    "id": "DPkdoFMSLWV8",
    "outputId": "c6137dc2-180e-4143-c937-085d741c1923"
   },
   "outputs": [],
   "source": [
    "import mglearn\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "mglearn.tools.visualize_coefficients(logistic.coef_, feature_names, n_top_features=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 301
    },
    "id": "aSu4RevWLWqj",
    "outputId": "aa93a903-d335-41e9-aa82-194406aa5c7c"
   },
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "# Create a dictionary with word frequencies\n",
    "word_frequencies = dict(zip(feature_names, X_train.sum(axis=0).A1))\n",
    "\n",
    "# Create and generate a word cloud image:\n",
    "#wordcloud = WordCloud().generate(text)\n",
    "wordcloud = WordCloud(width=750, height=400, background_color='white').generate_from_frequencies(word_frequencies)\n",
    "\n",
    "# Display the generated image:\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.savefig(\"wordcloud7.png\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VJp04ehALkJW",
    "outputId": "39403c3e-e122-4fdd-cb44-92543e98db3a"
   },
   "outputs": [],
   "source": [
    "feature_names = vectorizer.get_feature_names_out()\n",
    "print(len(feature_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CPkOzIWoSd-9",
    "outputId": "5f5cf04d-1376-4b19-a0df-411d63881fde"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score, precision_score, \\\n",
    "ConfusionMatrixDisplay, confusion_matrix\n",
    "y_pred=logistic.predict(X_test)\n",
    "\n",
    "print(f'Accuracy  :{logistic.score(X_test,y_test):.4f}' )\n",
    "print(f'Precision :{precision_score(y_test, y_pred):.4f}' )\n",
    "print(f'Recall  :{recall_score(y_test, y_pred):.4f}' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 466
    },
    "id": "sjDK_eZKSl9Q",
    "outputId": "4e6fef15-08a0-4567-ce23-99965f33c75a"
   },
   "outputs": [],
   "source": [
    "#Display a confusion matrix:\n",
    "tn, fp, fn, tp=confusion_matrix(y_test,y_pred).ravel()\n",
    "cm=np.array([[tp,fn],[fp,tn]])\n",
    "display_labels = [1, 0]\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=display_labels)\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HNDSZblbSZgu"
   },
   "source": [
    "# Illustration alternative classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2ohQB8RmSsr6",
    "outputId": "96524834-21ef-44da-c8ce-01ca11c40a16"
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp=MLPClassifier()\n",
    "mlp.fit(X_train, y_train)\n",
    "mlp.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RNy1m_RuptOn",
    "outputId": "d23a7e28-e133-430b-e55b-8162bfb95bb0"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtc=DecisionTreeClassifier(max_depth=10)\n",
    "dtc.fit(X_train, y_train)\n",
    "dtc.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1amSmYygp2PI",
    "outputId": "5e4f9c21-b5d7-4daa-ed43-2913bd674936"
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn=KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)\n",
    "knn.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp=spacy.load(\"en_core_web_sm\", disable=[\"parser\", \"ner\", \"textcat\"])\n",
    "\n",
    "def lemma_tokenizer(doc):\n",
    "    \"\"\"Returns a list of lemmatized tokens extracted from the document\"\"\"\n",
    "    tokens=[]\n",
    "    for token in nlp(doc):\n",
    "        if not token.is_punct:\n",
    "            tokens.append(token.lemma_)\n",
    "    return tokens\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vectorizer=TfidfVectorizer(tokenizer=lemma_tokenizer, token_pattern=None, min_df=5)\n",
    "tfidf_vectorizer.fit(df_train['review'])\n",
    "X_train=tfidf_vectorizer.transform(df_train['review'])\n",
    "X_test=tfidf_vectorizer.transform(df_test['review'])\n",
    "logistic.fit(X_train, y_train)\n",
    "logistic.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "# Create a dictionary with word frequencies\n",
    "word_frequencies = dict(zip(feature_names, X_train.sum(axis=0).A1))\n",
    "\n",
    "# Create and generate a word cloud image:\n",
    "#wordcloud = WordCloud().generate(text)\n",
    "wordcloud = WordCloud(width=750, height=400, background_color='white').generate_from_frequencies(word_frequencies)\n",
    "\n",
    "# Display the generated image:\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.savefig(\"wordcloud8.png\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_value=X_train.max(axis=0).toarray().ravel()\n",
    "sorted_by_tfidf=max_value.argsort()\n",
    "feature_names=np.array(tfidf_vectorizer.get_feature_names_out())\n",
    "feature_names[sorted_by_tfidf[:20]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names[sorted_by_tfidf[-20:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PFjdmVgSLlL6"
   },
   "source": [
    "# Named Entity Recognition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QfLxHOAdyPo8"
   },
   "outputs": [],
   "source": [
    "nlp=spacy.load(\"en_core_web_sm\")\n",
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\"\"\"We have audited the accompanying consolidated balance sheets of NVIDIA Corporation and its subsidiaries (the “Company”) \n",
    "as of January 28, 2024 and January 29, 2023, and the related consolidated statements of income, \n",
    "comprehensive income, shareholders' equity and cash flows for each of the three years in the period ended January 28,\n",
    "2024, including the related notes and financial statement schedule listed in the index appearing under Item 15(a)(2)\n",
    "(collectively referred to as the “consolidated financial statements”). We also have audited the Company's internal control\n",
    "over financial reporting as of January 28, 2024, based on criteria established in Internal Control - Integrated Framework\n",
    "(2013) issued by the Committee of Sponsoring Organizations of the Treadway Commission (COSO).\n",
    "\n",
    "In our opinion, the consolidated financial statements referred to above present fairly, in all material respects, the financial\n",
    "position of the Company as of January 28, 2024 and January 29, 2023, and the results of its operations and its cash flows\n",
    "for each of the three years in the period ended January 28, 2024 in conformity with accounting principles generally\n",
    "accepted in the United States of America. Also in our opinion, the Company maintained, in all material respects, effective\n",
    "internal control over financial reporting as of January\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 192
    },
    "id": "NtO32wLtzqdG",
    "outputId": "83e4f2d2-bd0a-49cc-9737-6e45f824edbc"
   },
   "outputs": [],
   "source": [
    "doc=nlp(text)\n",
    "displacy.render(doc, style='ent', jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ag1r98Hj1sXa",
    "outputId": "2c2a9397-464b-418a-c7cb-4b87eba07722"
   },
   "outputs": [],
   "source": [
    "for entity in doc.ents:\n",
    "    print(f\"{entity.text:-<{20}}{entity.label_:-<{20}}{str(spacy.explain(entity.label_))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FiOOINwhQ-u1",
    "outputId": "ad71c10f-9b3b-4a61-b5f0-55bd7ae6fc00"
   },
   "outputs": [],
   "source": [
    "print(\"Text \\t Lemma \\t P_o_S \\t Stop\")\n",
    "for token in doc[:20]:\n",
    "    print(token.text,\"\\t\", token.lemma_,\"\\t\", token.pos_,\"\\t\", token.is_stop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "okX9aY9xQ_h5"
   },
   "source": [
    "# Word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "import numpy as np\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "vectors = api.load('word2vec-google-news-300')\n",
    "\n",
    "# Compute cosine similarity\n",
    "def similarity(word1,word2):\n",
    "    cosine_similarity = dot(word1, word2) / (norm(word1) * norm(word2))\n",
    "    print(\"Cosine Similarity:\", cosine_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "king = vectors['king']\n",
    "queen = vectors['queen']\n",
    "man =  vectors['man']\n",
    "woman = vectors['woman']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors.similarity('custom_word', 'king')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity(king,queen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentence similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow_hub\n",
    "import tensorflow_hub as hub\n",
    "model = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder-large/5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence1=\"Audit quality equals the market-assessed joint probability that a given auditor will both (a) discovers a breach in the client’s accounting system, and (b) report the breach.\"\n",
    "sentence2=\"Audit quality is the market-perceived likelihood that an auditor will both (a) detect a violation in the client’s accounting system and (b) disclose that violation\"\n",
    "sentences=[sentence1,sentence2]\n",
    "\n",
    "embeddings=model(sentences)\n",
    "\n",
    "similarity(embeddings[0],embeddings[1])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
